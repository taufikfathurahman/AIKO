{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Machine Learning\n",
    "\n",
    "> * Tujuan dari machine learning adalah untuk melakukan optimasi pada objective function.\n",
    "> * Terdapat dua kategori dari optimasi, yaitu:\n",
    "    1. First order (first derivative/gradient)\n",
    "    2. Seconda  order (second derivatice in the scalar case)\n",
    "> * Keduanya melakukan compute loss function dengan meminimalisasi perbedaan antara `real label` terhadap `predicted label` value melalu convex optimization (contoh : gradient descent, newton's method)\n",
    "\n",
    "###### How about unlabeled data?\n",
    "\n",
    "<img src=\"https://s-media-cache-ak0.pinimg.com/736x/8b/23/3e/8b233e2d7f26b00d0c594894917a127b--supervised-learning-variables.jpg\" width=500/>\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/summit2014presentationfinal-141031070327-conversion-gate02/95/set-your-content-straight-28-638.jpg?cb=1414739431\" width=500/>\n",
    "\n",
    "> Clustering - Merupakan type unsupervised learning yang terkenal. Dalam clustering algorithm akan mencoba untuk mencari `natural groupings` dalam data. Points data yang serupa (menurut beberapa kesamaan) akan dianggap dalam satu kelompok yang sama, dan kelompok ini yang dinamakan sebagai clusters.\n",
    "\n",
    "# K-Mean Clustering\n",
    "\n",
    "K-mean clustering adalah salah satu \"unsupervised machine learning algorithms\" yang paling sederhana dan populer. Tujuan dari algoritma ini adalah uuk menemukan group dalam data, dengan jumlah group yang diwakili oleh variable ```K```. Variable ```K``` sendiri adalah jumlah cluster yang diinginkan.\n",
    "\n",
    "### # Proses K-Mean Clustering\n",
    "![kmean](http://konukoii.com/blog/wp-content/uploads/2017/01/RunyanKmeans.gif \"Kmean process\")\n",
    "\n",
    "Untuk memproses data algoritma K-means Clustering, data dimulai dengan kelompok pertama centroid yang dipilih secara acak, yang digunakan sebagai titik awal untuk setiap cluster, dan kemudian melakukan perhitungan berulang untuk mengoptimalkan posisi centroid.\n",
    "\n",
    "```\n",
    "    input: K, set of points (x1 ... xn)\n",
    "    place centroids c1 .. ck at random locations\n",
    "    repeat until convergence:\n",
    "        for each point xi:\n",
    "            * find nearest centroid cj\n",
    "            * assign the point ci to cluster j\n",
    "        for each cluster j = 1 ... k:\n",
    "            * new centroid cj= mean of all points xi assigned to cluster j in previous step\n",
    "    stop when non of the cluster assignments change\n",
    "```\n",
    "Proses akan berhenti mengoptimalkan cluster ketika:\n",
    "1. Centroid telah stabil-tidak ada perubahan dalam nilai-nilai mereka karena pengelompokan telah berhasil.\n",
    "2. Jumlah iterasi yang ditentukan telah tercapai.\n",
    "\n",
    "#### ## Menentukan K terbaik\n",
    "\n",
    "1. Jika kita telaah mengetahui kelas yang diinginkan, maka itu lah yang akan menjadi K.\n",
    "2. Jika tidak maka `Elbow` method menjadi salah satu jalan yang popular digunakan.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/0*jWe7Ns_ubBpOaemM.png\" width=500/>\n",
    "\n",
    "Elbow method mencari nilai K terbaik dengan cara mecoba K-means clustering terhadap dataset dengan range value dari K (Kita ambil contoh, K mulai dari 1 sampai 10), dan untuk setiap value dari K dihitung jumlah dari hasil akar error (SSE), yaitu:\n",
    "\n",
    "```\n",
    "   var sse = {};\n",
    "   for 9var k = 1; k <= maxK; ++k) {\n",
    "       sse[k] = 0;\n",
    "       clusters = kmeans(dataser, k);\n",
    "       clusters.forEach(function(cluster) {\n",
    "           mean = clusterMean(cluster);\n",
    "           cluster.forEach(function(datapoint) {\n",
    "               sse[k] += Math.pow(datapoint - mean, 2);\n",
    "           });\n",
    "        });\n",
    "   }\n",
    "```\n",
    "Setelah SSE dari setiap K value, lakukan line plot. Jika line chart yang dihasilkan berbentuk menyerupai lengan, maka bagian \"elbow\" dari lengan merupakan best value untuk dijadikan `K`.\n",
    "\n",
    "#### ## Bagaimana jarak antara centroids dan data points diukur?\n",
    "\n",
    "Jawabannya adalah `Euclidean Distance`. Karena K-Means meminimalkan varians dalam cluster dan jika kita lihat definisi dari varians, itu identik dengan jumlah jarak euclidean kudrat dari pusat.\n",
    "\n",
    "### # Kapan K-Means Dapat digunakan?\n",
    "\n",
    "- Data yang dimiliki adalah numerik. \n",
    "- Jika label dari data yang dimiliki tidak diketahui.\n",
    "- Berguna ketika diketahui berapa banyak clusters yang sebenarnya muncul pada space yang diinginkan.\n",
    "- Ketika data yang dimiliki meruaak `multivariate data`. dapat diterakan pada data 1 dimensi namun tidak akan terlalu cerdas lagi.\n",
    "\n",
    "### # Hasil dari K-Mean Clustering\n",
    "1. Centroid dari cluster K, yang dapat digunakan untuk memberi label data baru.\n",
    "2. Label untuk data pelatihan (setiap titik data ditugaskan satu cluster)\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/cIDB3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <> Load Hough Circle Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./aiko_circle_detection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "try:\n",
    "    ht_result = np.genfromtxt(\"Result/Result.csv\", delimiter=\",\", skip_header=1)\n",
    "except:\n",
    "    start = time.time()\n",
    "    execute_ht()\n",
    "    ht_result = np.genfromtxt(\"Result/Result.csv\", delimiter=\",\", skip_header=1)\n",
    "    end = time.time()\n",
    "    print('Time spent for Hough Circle Transform =>', end - start, 's')\n",
    "    \n",
    "X = ht_result[:,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Useful Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-Means Clustering Without E-M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=6, max_iter=1000, algorithm='auto')\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save K-Means Clustering 1 result to csv\n",
    "df = pd.read_csv('Result/Result.csv')\n",
    "df['Wood Class'] = y_kmeans\n",
    "df.to_excel('Result/Kmean1.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering With E-M\n",
    "\n",
    "Expectation-maximation(E-M) Merupakan algoritma yang powerful dalam berbagai konteks dalam data science. K-Mean adalah algoritma yang sangat sederhana dan mudah dipahami, dan akan mudah untuk diaplikasikan. Pendekatan Expectation-Maximization (E-M) akan terdiri dari beberapa procedure sebagai berikut ini:\n",
    "```\n",
    "    1. Menebak beberapa cluster centers\n",
    "    2. Repeat until converged\n",
    "        * E-Step : Menetapkan points terhadap cluster center terdekat\n",
    "        * M-Step : Mengatur pusat cluster ke mean\n",
    "```\n",
    "> \"E-Step\" atau \"Expectation Step\" diberinama demikian karena didalamna melibatkan pembaruan \"expectation\" yang dimiliki oleh masing-masig cluster. \n",
    "\n",
    "> \"M-Step\" atau \"Maximization Step\" diberi nama demikian karena melibatkan \"maximizing\" bebrapa fitness function yang menentukan lokasi cluster centers. Maximization dicapai denan mengambil rata-rata sederhana dari setiap data di sekitar cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clusters(X, n_clusters, rseed=50):\n",
    "    # 1. Randomly choose clusters\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    i = rng.permutation(X.shape[0])[:n_clusters]\n",
    "    centers = X[i]\n",
    "    \n",
    "    while True:\n",
    "        # 2a. Assign labels based on closest center\n",
    "        labels = pairwise_distances_argmin(X, centers)\n",
    "        \n",
    "        # 2b. Find new centers from means of points\n",
    "        new_centers = np.array([X[labels == i].mean(0)\n",
    "                                for i in range(n_clusters)])\n",
    "        \n",
    "        # 2c. Check for convergence\n",
    "        if np.all(centers == new_centers):\n",
    "            break\n",
    "        centers = new_centers\n",
    "    \n",
    "    return centers, labels\n",
    "\n",
    "centers, labels = find_clusters(X, 6)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels,\n",
    "            s=50, cmap='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 1], \n",
    "            c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save K-Means result to csv\n",
    "df2 = pd.read_csv('Result/Result.csv')\n",
    "df2['Wood Class'] = labels\n",
    "df2.to_excel('Result/Kmean2.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > K-Means Clustering : E-M (Step by Step Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "rng = np.random.RandomState(50)\n",
    "i = rng.permutation(X.shape[0])[:6]\n",
    "centers = X[i]\n",
    "\n",
    "def draw_points(ax, c, factor=1):\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=c, cmap='viridis',\n",
    "               s=50 * factor, alpha=0.3)\n",
    "    \n",
    "def draw_centers(ax, centers, factor=1, alpha=1.0):\n",
    "    ax.scatter(centers[:, 0], centers[:, 1],\n",
    "               c=np.arange(6), cmap='viridis', s=200 * factor,\n",
    "               alpha=alpha)\n",
    "    ax.scatter(centers[:, 0], centers[:, 1],\n",
    "               c='black', s=50 * factor, alpha=alpha)\n",
    "\n",
    "def make_ax(fig, gs):\n",
    "    ax = fig.add_subplot(gs)\n",
    "    ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 4))\n",
    "gs = plt.GridSpec(4, 15, left=0.02, right=0.98, bottom=0.05, top=0.95, wspace=0.2, hspace=0.2)\n",
    "ax0 = make_ax(fig, gs[:4, :4])\n",
    "ax0.text(0.98, 0.98, \"Random Initialization\", transform=ax0.transAxes,\n",
    "         ha='right', va='top', size=16)\n",
    "draw_points(ax0, 'gray', factor=2)\n",
    "draw_centers(ax0, centers, factor=2)\n",
    "\n",
    "for i in range(3):\n",
    "    ax1 = make_ax(fig, gs[:2, 4 + 2 * i:6 + 2 * i])\n",
    "    ax2 = make_ax(fig, gs[2:, 5 + 2 * i:7 + 2 * i])\n",
    "    \n",
    "    # E-step\n",
    "    y_pred = pairwise_distances_argmin(X, centers)\n",
    "    draw_points(ax1, y_pred)\n",
    "    draw_centers(ax1, centers)\n",
    "    \n",
    "    # M-step\n",
    "    new_centers = np.array([X[y_pred == i].mean(0) for i in range(6)])\n",
    "    draw_points(ax2, y_pred)\n",
    "    draw_centers(ax2, centers, alpha=0.3)\n",
    "    draw_centers(ax2, new_centers)\n",
    "    for i in range(6):\n",
    "        ax2.annotate('', new_centers[i], centers[i],\n",
    "                     arrowprops=dict(arrowstyle='->', linewidth=1))\n",
    "        \n",
    "    \n",
    "    # Finish iteration\n",
    "    centers = new_centers\n",
    "    ax1.text(0.95, 0.95, \"E-Step\", transform=ax1.transAxes, ha='right', va='top', size=14)\n",
    "    ax2.text(0.95, 0.95, \"M-Step\", transform=ax2.transAxes, ha='right', va='top', size=14)\n",
    "\n",
    "\n",
    "# Final E-step    \n",
    "y_pred = pairwise_distances_argmin(X, centers)\n",
    "axf = make_ax(fig, gs[:4, -4:])\n",
    "draw_points(axf, y_pred, factor=2)\n",
    "draw_centers(axf, centers, factor=2)\n",
    "axf.text(0.98, 0.98, \"Final Clustering\", transform=axf.transAxes,\n",
    "         ha='right', va='top', size=16)\n",
    "\n",
    "fig.savefig('Result/expectation-maximization-result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
