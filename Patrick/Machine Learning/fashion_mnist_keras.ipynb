{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2NPAI4jZZgi"
   },
   "source": [
    "# Modern Deep Learning: \n",
    "# Classify Fashion-MNIST with a simple CNN in Keras\n",
    "\n",
    "<br> By Margaret Maynard-Reid, 4/24/2018\n",
    "\n",
    "![alt text](https://github.com/margaretmz/deep-learning/blob/master/images/modern%20dl_fash-mnist_keras.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18xLQCydFHqi"
   },
   "source": [
    "## Why Jupyter Notebook?\n",
    "\n",
    "\n",
    "*   Interactive programming in the web browser\n",
    "*   Great for visualization\n",
    "*   Great for collabration\n",
    "*   Popular tool for studying machine learning / deep learning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLMRPLVCFwEc"
   },
   "source": [
    "## Why Fashion-MNIST?\n",
    "\n",
    "\n",
    "*   MNIST is too easy\n",
    "*   MNIST is overused\n",
    "*   MNIST can not represent modern Computer Vision tasks\n",
    "\n",
    "Read more about the Fashion-MINST dataset in this paper [here](https://arxiv.org/abs/1708.07747) (**Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ixyte299ZZgk"
   },
   "source": [
    "## Notebook Overview\n",
    "\n",
    "<br> **Notebook location on github**: https://github.com/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb\n",
    "\n",
    "This is a tutorial of how to classify **fashion_mnist** data with a simple **Convolutional Neural Network** in Keras. \n",
    "Keras is now part of the core TensorFlow library, in addition to being an independent open source project. \n",
    "\n",
    "The [fashion_mnist](https://github.com/zalandoresearch/fashion-mnist) data: \n",
    "60,000 train and 10,000 test data with 10 categories. Each gray-scale image is 28x28.\n",
    "\n",
    "<br> **Label**\t**Description**\n",
    "<br> 0 T-shirt/top\n",
    "<br> 1 Trouser\n",
    "<br> 2 Pullover\n",
    "<br> 3 Dress\n",
    "<br> 4 Coat\n",
    "<br> 5 Sandal\n",
    "<br> 6 Shirt\n",
    "<br> 7 Sneaker\n",
    "<br> 8 Bag\n",
    "<br> 9 Ankle boot\n",
    "\n",
    "Each gray-scale image is 28x28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "toc",
    "id": "1jQGPl2l7kF7"
   },
   "source": [
    ">[Modern Deep Learning:](#scrollTo=r2NPAI4jZZgi)\n",
    "\n",
    ">[Classify Fashion-MNIST with a simple CNN in Keras](#scrollTo=r2NPAI4jZZgi)\n",
    "\n",
    ">>[Why Jupyter Notebook?](#scrollTo=18xLQCydFHqi)\n",
    "\n",
    ">>[Why Fashion-MNIST?](#scrollTo=XLMRPLVCFwEc)\n",
    "\n",
    ">>[Notebook Overview](#scrollTo=Ixyte299ZZgk)\n",
    "\n",
    ">>[Download the fashion_mnist data](#scrollTo=LbCigZtNZZgl)\n",
    "\n",
    ">>[Visualize the data](#scrollTo=tWORMSC8FDR4)\n",
    "\n",
    ">>[Data normalization](#scrollTo=Zx-Ee6LHZZgt)\n",
    "\n",
    ">>[Split the data into train/validation/test data sets](#scrollTo=CFlNHktHBtru)\n",
    "\n",
    ">>[Create the model architecture](#scrollTo=HhalcO03ZZg3)\n",
    "\n",
    ">>[Compile the model](#scrollTo=FhxJ5dinZZg8)\n",
    "\n",
    ">>[Train the model](#scrollTo=DtOvh3YVZZg_)\n",
    "\n",
    ">>[Load Model with the best validation accuracy](#scrollTo=e-MGLwZQy05d)\n",
    "\n",
    ">>[Test Accuracy](#scrollTo=9RTRkan4yq5H)\n",
    "\n",
    ">>[Visualize prediction](#scrollTo=oJv7XEk10bOv)\n",
    "\n",
    ">>[Congragulations!](#scrollTo=8AehWdRAVKN5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbCigZtNZZgl"
   },
   "source": [
    "## Download the fashion_mnist data\n",
    "First let's install TensorFlow version 1.8.0 and import Tensorflow. Then we download fashion-mnist which is one of the Keras datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "d44TznbgZZgm",
    "outputId": "b722a31e-6c74-45d1-b07c-4bafb4c29a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWORMSC8FDR4"
   },
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "aFe4wHGRFKle",
    "outputId": "76e7edaa-60db-4cad-c567-277013795a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "60000 train set\n",
      "10000 test set\n",
      "y = 2 Pullover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x259d7b36f28>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zx-Ee6LHZZgt"
   },
   "source": [
    "## Data normalization\n",
    "Normalize the data dimensions so that they are of approximately the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNh5NIckZZgu"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "LMSg53fiZZgx",
    "outputId": "c3cdfb81-6db1-42c9-a93e-679e6d8ba933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train data - 60000\n",
      "Number of test data - 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of train data - \" + str(len(x_train)))\n",
    "print(\"Number of test data - \" + str(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFlNHktHBtru"
   },
   "source": [
    "## Split the data into train/validation/test data sets\n",
    "\n",
    "\n",
    "*   Training data - used for training the model\n",
    "*   Validation data - used for tuning the hyperparameters and evaluate the models\n",
    "*   Test data - used to test the model after the model has gone through initial vetting by the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "1ShU787gZZg0",
    "outputId": "2016e59c-a88b-4ecd-c9fa-1177011877d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (55000, 28, 28, 1) y_train shape: (55000, 10)\n",
      "55000 train set\n",
      "5000 validation set\n",
      "10000 test set\n"
     ]
    }
   ],
   "source": [
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhalcO03ZZg3"
   },
   "source": [
    "## Create the model architecture\n",
    "\n",
    "There are two APIs for defining a model in Keras:\n",
    "1. [Sequential model API](https://keras.io/models/sequential/)\n",
    "2. [Functional API](https://keras.io/models/model/)\n",
    "\n",
    "In this notebook we are using the Sequential model API. \n",
    "If you are interested in a tutorial using the Functional API, checkout Sara Robinson's blog [Predicting the price of wine with the Keras Functional API and TensorFlow](https://medium.com/tensorflow/predicting-the-price-of-wine-with-the-keras-functional-api-and-tensorflow-a95d1c2c1b03).\n",
    "\n",
    "In defining the model we will be using some of these Keras APIs:\n",
    "*   Conv2D() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D/) - create a convolutional layer \n",
    "*   Pooling() [link text](https://keras.io/layers/pooling/) - create a pooling layer \n",
    "*   Dropout() [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) - apply drop out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "colab_type": "code",
    "id": "QgTZ47SsZZg4",
    "outputId": "685749b8-c326-495a-c9c2-eb523173bd5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhxJ5dinZZg8"
   },
   "source": [
    "## Compile the model\n",
    "Configure the learning process with compile() API before training the model. It receives three arguments:\n",
    "\n",
    "*   An optimizer \n",
    "*   A loss function \n",
    "*   A list of metrics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQUlOa8cZZg9"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtOvh3YVZZg_"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Now let's train the model with fit() API.\n",
    "\n",
    "We use  the [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) API to save the model after every epoch. Set \"save_best_only = True\" to save only when the validation accuracy improves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "colab_type": "code",
    "id": "ZTmapAttZZhA",
    "outputId": "08770dfd-10f0-4fad-81a6-0b0333086281"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0707 16:34:14.952619  7932 deprecation.py:323] From c:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1251: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0707 16:34:15.184883  7932 deprecation.py:323] From c:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py:460: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Apply a constraint manually following the optimizer update step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at c:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1654) ]]\n\t [[dropout_1/cond/then/_11/dropout/mul-0-0-TransposeNCHWToNHWC-LayoutOptimizer/_50]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at c:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1654) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_1330]\n\nFunction call stack:\nkeras_scratch_graph -> keras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fecc635deeed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m          \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m          \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m          callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3497\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3498\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3499\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3501\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    613\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m    614\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m--> 615\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args)\u001b[0m\n\u001b[0;32m    457\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[0;32m    458\u001b[0m                    \"config_proto\", config),\n\u001b[1;32m--> 459\u001b[1;33m             ctx=ctx)\n\u001b[0m\u001b[0;32m    460\u001b[0m       \u001b[1;31m# Replace empty list with None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at c:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1654) ]]\n\t [[dropout_1/cond/then/_11/dropout/mul-0-0-TransposeNCHWToNHWC-LayoutOptimizer/_50]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d/Conv2D (defined at c:\\users\\babyanaconda\\anaconda3\\envs\\babytf_gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1654) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_1330]\n\nFunction call stack:\nkeras_scratch_graph -> keras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-MGLwZQy05d"
   },
   "source": [
    "## Load Model with the best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD1tecxUZZhE"
   },
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "model.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RTRkan4yq5H"
   },
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VZtqBqFFy62R",
    "outputId": "7cc9a4dd-1641-4a94-f4ce-c209cf9a142d"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJv7XEk10bOv"
   },
   "source": [
    "## Visualize prediction\n",
    "Now let's visualize the prediction using the model you just trained. \n",
    "First we get the predictions with the model from the test data.\n",
    "Then we print out 15 images from the test data set, and set the titles with the prediction (and the groud truth label).\n",
    "If the prediction matches the true label, the title will be green; otherwise it's displayed in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "id": "QwNmlfIC0YxM",
    "outputId": "dc74804f-8871-43a6-ea37-3ef4d57d413f"
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "\n",
    "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
    "figure = plt.figure(figsize=(20, 8))\n",
    "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(x_test[index]))\n",
    "    predict_index = np.argmax(y_hat[index])\n",
    "    true_index = np.argmax(y_test[index])\n",
    "    # Set the title for each image\n",
    "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
    "                                  fashion_mnist_labels[true_index]),\n",
    "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AehWdRAVKN5"
   },
   "source": [
    "## Congragulations! \n",
    "You have successfully trained a CNN to classify fashion-MNIST with near 90% accuracy."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fashion_mnist_keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
